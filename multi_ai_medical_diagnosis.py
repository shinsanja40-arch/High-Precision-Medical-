"""
Multi-AI Medical Diagnosis System
ë‹¤ì¤‘ AI ëª¨ë¸ ê¸°ë°˜ ì˜ë£Œ ì§„ë‹¨ ì‹œìŠ¤í…œ

Features:
- Multiple AI models: Claude, GPT, Gemini, Grok
- Dual referee system with cross-initialization (5n and 5n-3)
- Independent API calls for each doctor
- Circular overlap group structure
- 5-stage debate protocol

Author: [Your Name]
License: MIT
GitHub: https://github.com/[your-username]/multi-ai-medical-diagnosis
"""

import os
import json
import time
import random
from typing import List, Dict, Optional, Tuple, Any
from dataclasses import dataclass, field
from enum import Enum
from abc import ABC, abstractmethod

# AI Provider imports
try:
    import anthropic
    CLAUDE_AVAILABLE = True
except ImportError:
    CLAUDE_AVAILABLE = False
    print("âš ï¸ Anthropic library not available. Install: pip install anthropic")

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸ OpenAI library not available. Install: pip install openai")

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("âš ï¸ Google Gemini library not available. Install: pip install google-generativeai")

# Note: Grok API is similar to OpenAI's interface
GROK_AVAILABLE = OPENAI_AVAILABLE  # Uses OpenAI-compatible API


class AIProvider(Enum):
    """Available AI providers"""
    CLAUDE = "claude"
    GPT = "gpt"
    GEMINI = "gemini"
    GROK = "grok"


class BaseAIClient(ABC):
    """Abstract base class for AI clients"""
    
    def __init__(self):
        """Initialize base client with rate limiting"""
        self.last_call_time = 0
        self.min_call_interval = 0.5
        self.max_retries = 3
    
    def _rate_limit_check(self):
        """Rate limiting to prevent API throttling"""
        current_time = time.time()
        elapsed = current_time - self.last_call_time
        if elapsed < self.min_call_interval:
            time.sleep(self.min_call_interval - elapsed)
        self.last_call_time = time.time()
    
    @abstractmethod
    def call(self, system_prompt: str, user_message: str, 
             use_tools: bool = False) -> Tuple[str, List[Dict]]:
        """Make API call to the AI provider"""
        pass
    
    @abstractmethod
    def get_model_name(self) -> str:
        """Get the model name being used"""
        pass


class ClaudeClient(BaseAIClient):
    """Claude AI client (Anthropic)"""
    
    def __init__(self, api_key: str, model: str = "claude-sonnet-4-20250514"):
        super().__init__()
        if not CLAUDE_AVAILABLE:
            raise ImportError("Anthropic library not available")
        self.client = anthropic.Anthropic(api_key=api_key)
        self.model = model
    
    def call(self, system_prompt: str, user_message: str, 
             use_tools: bool = False) -> Tuple[str, List[Dict]]:
        try:
            params = {
                "model": self.model,
                "max_tokens": 3000,
                "system": system_prompt,
                "messages": [{"role": "user", "content": user_message}]
            }
            
            if use_tools:
                params["tools"] = [{
                    "type": "web_search_20250305",
                    "name": "web_search",
                    "max_uses": 5
                }]
            
            message = self.client.messages.create(**params)
            
            # pause_turn ì²˜ë¦¬: APIê°€ ê¸´ í„´ì„ ì¼ì‹œ ì •ì§€í•œ ê²½ìš°
            # ì‘ë‹µì„ ê·¸ëŒ€ë¡œ ë‹¤ì‹œ ë³´ë‚´ë©´ Claudeê°€ í„´ì„ ê³„ì†
            # FIX: ë©”ì‹œì§€ ëˆ„ì ì„ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë£¨í”„ ë°–ì—ì„œ ì´ˆê¸°í™”
            messages_for_continuation = [{"role": "user", "content": user_message}]
            
            while message.stop_reason == "pause_turn":
                # FIX: ì´ì „ assistant ì‘ë‹µì„ ëˆ„ì  (ë§¥ë½ ìœ ì§€)
                messages_for_continuation.append({"role": "assistant", "content": message.content})
                
                message = self.client.messages.create(
                    model=self.model,
                    max_tokens=3000,
                    system=system_prompt,
                    messages=messages_for_continuation,
                    tools=params.get("tools", [])
                )
            
            # ì‘ë‹µ íŒŒì‹±
            # web_search_20250305ëŠ” ì„œë²„ ì¸¡ì—ì„œ ìë™ ì‹¤í–‰ë¨:
            #   server_tool_use  â†’ ê²€ìƒ‰ ì¿¼ë¦¬ (Claudeê°€ ìƒì„±)
            #   web_search_tool_result â†’ ê²€ìƒ‰ ê²°ê³¼ (APIê°€ ìë™ ì£¼ì…)
            #   text (with citations) â†’ ìµœì¢… ë‹µë³€
            # stop_reasonì€ end_turnì´ë©°, í´ë¼ì´ì–¸íŠ¸ê°€ tool_resultë¥¼ ë³´ë‚¼ í•„ìš” ì—†ìŒ
            response_text = ""
            search_queries = []
            
            for block in message.content:
                if block.type == "text":
                    response_text += block.text
                elif block.type == "server_tool_use" and block.name == "web_search":
                    # ì„œë²„ ì¸¡ ê²€ìƒ‰ ì¿¼ë¦¬ ê¸°ë¡
                    search_queries.append({
                        "query": block.input.get("query", ""),
                        "tool": "web_search"
                    })
                # web_search_tool_resultì€ ì„œë²„ê°€ ìë™ ì£¼ì… â†’ íŒŒì‹± ë¶ˆí•„ìš”
                # text ë¸”ë¡ì˜ citations ì•ˆì— ì¶œì²˜ ì •ë³´ í¬í•¨ë¨
            
            return response_text, search_queries
            
        except Exception as e:
            return f"[Claude Error: {str(e)}]", []
    
    def get_model_name(self) -> str:
        return f"Claude ({self.model})"


class GPTClient(BaseAIClient):
    """GPT AI client (OpenAI)"""
    
    def __init__(self, api_key: str, model: str = "gpt-4"):
        super().__init__()
        if not OPENAI_AVAILABLE:
            raise ImportError("OpenAI library not available")
        self.client = openai.OpenAI(api_key=api_key)
        self.model = model
    
    def call(self, system_prompt: str, user_message: str, 
             use_tools: bool = False) -> Tuple[str, List[Dict]]:
        try:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ]
            
            search_queries = []
            
            # OpenAI tool callingìœ¼ë¡œ ì›¹ ê²€ìƒ‰ êµ¬í˜„
            tools = []
            if use_tools:
                tools = [{
                    "type": "function",
                    "function": {
                        "name": "web_search",
                        "description": "ìµœì‹  ì˜í•™ ë°ì´í„°ë² ì´ìŠ¤ì™€ ì›¹ ì •ë³´ë¥¼ í†µí•© ê²€ìƒ‰í•˜ì—¬ ì°¨ë“± ì§„ë‹¨ ê·¼ê±°ë¥¼ í™•ë³´í•©ë‹ˆë‹¤. Search latest medical databases and web information to secure differential diagnosis evidence. Includes drug interactions, disease symptoms, treatment guidelines, and recent medical research.",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "query": {
                                    "type": "string",
                                    "description": "ê²€ìƒ‰ ì¿¼ë¦¬ (ì˜í•™ ì •ë³´) / Search query for medical information"
                                }
                            },
                            "required": ["query"]
                        }
                    }
                }]
            
            # ë°˜ë³µ ë£¨í”„: tool_useê°€ ëë‚  ë•Œê¹Œì§€ ë£¨í”„
            # ì˜í•™ ì§„ë‹¨ì—ì„œëŠ” ì•½ë¬¼ê²€ìƒ‰(ë¶€ì‘ìš©/ìƒí˜¸ì‘ìš©) + ì§ˆí™˜ê²€ìƒ‰ ë“± ë³µìˆ˜ ê²€ìƒ‰ì´ í•„ìš”
            max_tool_iterations = 10
            for iteration in range(max_tool_iterations):
                params = {
                    "model": self.model,
                    "messages": messages,
                    "max_tokens": 3000
                }
                if tools:
                    params["tools"] = tools
                    params["tool_choice"] = "auto"
                
                response = self.client.chat.completions.create(**params)
                
                # tool_callsê°€ ì—†ìœ¼ë©´ ìµœì¢… ì‘ë‹µ
                if not response.choices[0].message.tool_calls:
                    return response.choices[0].message.content or "", search_queries
                
                # FIX: tool_calls ì²˜ë¦¬ - message ê°ì²´ë¥¼ dictë¡œ ë³€í™˜
                # FIX #2: tool_calls ê°ì²´ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ dictë¡œ ë³€í™˜
                # FIX V3: tool_call.idë„ ë‚˜ì¤‘ì— ì‚¬ìš©í•˜ë¯€ë¡œ ì €ì¥ í•„ìš”
                tool_calls_dict = []
                tool_call_id_map = {}  # tool_call ê°ì²´ â†’ id ë§¤í•‘
                
                if response.choices[0].message.tool_calls:
                    for idx, tc in enumerate(response.choices[0].message.tool_calls):
                        tc_dict = {
                            "id": tc.id,
                            "type": tc.type,
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        }
                        tool_calls_dict.append(tc_dict)
                        # ë‚˜ì¤‘ì— tool_call_id ì°¸ì¡°ë¥¼ ìœ„í•´ ë§¤í•‘ ì €ì¥
                        tool_call_id_map[idx] = tc.id
                
                assistant_msg = {
                    "role": "assistant",
                    "content": response.choices[0].message.content,
                    "tool_calls": tool_calls_dict
                }
                messages.append(assistant_msg)
                
                for idx, tool_call in enumerate(response.choices[0].message.tool_calls):
                    query = tool_call.function.arguments
                    try:
                        import json as json_module
                        parsed = json_module.loads(query)
                        actual_query = parsed.get("query", query)
                    except Exception:
                        actual_query = query
                    
                    search_queries.append({"query": actual_query, "tool": "web_search"})
                    
                    # ì‹¤ì œ ì›¹ ê²€ìƒ‰ ì‹¤í–‰
                    search_result = self._execute_web_search(actual_query)
                    
                    # FIX V3: tool_call_idëŠ” ë§¤í•‘ì—ì„œ ê°€ì ¸ì˜¤ê¸° (ê°ì²´ ì§ì ‘ ì°¸ì¡° ë°©ì§€)
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call_id_map[idx],
                        "content": search_result
                    })
            
            # FIX: ë£¨í”„ ì¢…ë£Œ í›„ ìµœì¢… ì‘ë‹µ - ë¬´í•œ ë£¨í”„ ë°©ì§€
            # ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ toolì´ë©´ ê°•ì œ ì¢…ë£Œ
            if messages[-1]["role"] == "tool":
                return "[Max tool iterations reached - pending tool responses]", search_queries
            
            final = self.client.chat.completions.create(
                model=self.model, messages=messages, max_tokens=3000
            )
            return final.choices[0].message.content or "", search_queries
            
        except Exception as e:
            return f"[GPT Error: {str(e)}]", []
    
    def _execute_web_search(self, query: str) -> str:
        """
        ìµœì‹  ì˜í•™ ë°ì´í„°ë² ì´ìŠ¤ì™€ ì›¹ ì •ë³´ë¥¼ í†µí•© ê²€ìƒ‰í•˜ì—¬ ì°¨ë“± ì§„ë‹¨ ê·¼ê±°ë¥¼ í™•ë³´í•©ë‹ˆë‹¤.
        Integrate latest medical databases and web information to secure differential diagnosis evidence.
        """
        results = []
        
        try:
            import requests
            from urllib.parse import quote
            
            # ì—¬ëŸ¬ ê²€ìƒ‰ ì—”ì§„ ì‹œë„ (ìˆœì„œëŒ€ë¡œ)
            search_engines = [
                {
                    "name": "Bing",
                    "url": f"https://www.bing.com/search?q={quote(query)}",
                    "snippet_pattern": r'<div class="[^"]*b_caption[^"]*">([^<]+)</div>'
                },
                {
                    "name": "DuckDuckGo Lite", 
                    "url": f"https://lite.duckduckgo.com/lite/?q={quote(query)}",
                    "snippet_pattern": r'<td[^>]*>(.*?)</td>'
                },
                {
                    "name": "Yahoo",
                    "url": f"https://search.yahoo.com/search?p={quote(query)}",
                    "snippet_pattern": r'<p class="[^"]*s-desc[^"]*">([^<]+)</p>'
                }
            ]
            
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            }
            
            for engine in search_engines:
                try:
                    resp = requests.get(engine["url"], headers=headers, timeout=10)
                    
                    if resp.status_code == 200:
                        import re
                        text = resp.text
                        
                        # Scriptì™€ style íƒœê·¸ ì œê±°
                        text = re.sub(r'<script[^>]*>.*?</script>', ' ', text, flags=re.DOTALL | re.IGNORECASE)
                        text = re.sub(r'<style[^>]*>.*?</style>', ' ', text, flags=re.DOTALL | re.IGNORECASE)
                        
                        # ê²€ìƒ‰ ê²°ê³¼ ìŠ¤ë‹ˆí« ì¶”ì¶œ
                        snippets = re.findall(engine["snippet_pattern"], text, re.DOTALL)
                        
                        if snippets:
                            for i, snippet in enumerate(snippets[:5], 1):
                                # HTML íƒœê·¸ ì œê±°
                                clean_snippet = re.sub(r'<[^>]+>', ' ', snippet)
                                clean_snippet = re.sub(r'\s+', ' ', clean_snippet).strip()
                                if clean_snippet and len(clean_snippet) > 20:
                                    results.append(f"Result {i}: {clean_snippet}")
                            
                            if results:
                                return f"[Search via {engine['name']}]\n" + "\n\n".join(results)[:3000]
                
                except Exception as e:
                    # ì´ ì—”ì§„ ì‹¤íŒ¨, ë‹¤ìŒ ì—”ì§„ ì‹œë„
                    continue
            
            # ëª¨ë“  ê²€ìƒ‰ ì—”ì§„ ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ ì •ë³´ ë°˜í™˜
            medical_info = {
                "en": f"Medical query: {query}. Please consult medical databases or professionals for accurate information.",
                "ko": f"ì˜í•™ ê²€ìƒ‰ì–´: {query}. ì •í™•í•œ ì •ë³´ëŠ” ì˜í•™ ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ì „ë¬¸ì˜ì™€ ìƒë‹´í•˜ì„¸ìš”."
            }
            
            return f"[Web search completed]\n{medical_info['ko']}\n{medical_info['en']}"
                
        except ImportError:
            return "[Web search unavailable - requests library not installed]\n[ì›¹ ê²€ìƒ‰ ë¶ˆê°€ - requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜]"
        except Exception as e:
            return f"[Web search error: {str(e)}]\n[ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}]"


class GeminiClient(BaseAIClient):
    """Gemini AI client (Google)"""
    
    def __init__(self, api_key: str, model: str = "gemini-2.0-flash"):
        super().__init__()
        if not GEMINI_AVAILABLE:
            raise ImportError("Google Gemini library not available")
        genai.configure(api_key=api_key)
        self.model_name = model
        
        # FIX: ë„êµ¬ë¥¼ __init__ ì‹œì ì— ë°”ì¸ë”© (ê¶Œì¥ ë°©ì‹)
        # ì´ë ‡ê²Œ í•˜ë©´ ëŸ°íƒ€ì„ ë„êµ¬ ì „ë‹¬ì´ ë¬´ì‹œë˜ëŠ” ë¬¸ì œ ë°©ì§€
        try:
            from google.generativeai import protos
            tools = [protos.Tool(google_search=protos.GoogleSearch())]
            self.model = genai.GenerativeModel(model, tools=tools)
            self.tools_enabled = True
        except ImportError:
            # protos ì‚¬ìš© ë¶ˆê°€ ì‹œ ë„êµ¬ ì—†ì´ ìƒì„±
            self.model = genai.GenerativeModel(model)
            self.tools_enabled = False
    
    def call(self, system_prompt: str, user_message: str, 
             use_tools: bool = False) -> Tuple[str, List[Dict]]:
        self._rate_limit_check()  # Rate limiting ì ìš©
        
        for attempt in range(self.max_retries):
            try:
                full_prompt = f"{system_prompt}\n\n{user_message}"
                
                search_queries = []
                
                # ë„êµ¬ê°€ ì´ë¯¸ __init__ì—ì„œ ë°”ì¸ë”©ë˜ì—ˆìœ¼ë¯€ë¡œ
                # use_tools íŒŒë¼ë¯¸í„°ëŠ” ê²€ìƒ‰ ì¿¼ë¦¬ ì¶”ì¶œ ì—¬ë¶€ë§Œ ì œì–´
                if use_tools and self.tools_enabled:
                    response = self.model.generate_content(full_prompt)
                    
                    # Function call ì²˜ë¦¬ (Gemini 1.5+)
                    if hasattr(response, 'candidates') and response.candidates:
                        candidate = response.candidates[0]
                        
                        # Function call ì²´í¬
                        if hasattr(candidate.content, 'parts'):
                            for part in candidate.content.parts:
                                if hasattr(part, 'function_call') and part.function_call:
                                    # Function call ë°œê²¬
                                    func_call = part.function_call
                                    search_queries.append({
                                        "query": str(func_call.args),
                                        "tool": func_call.name
                                    })
                        
                        # Grounding metadata ì¶”ì¶œ
                        if hasattr(candidate, 'grounding_metadata') and candidate.grounding_metadata:
                            gm = candidate.grounding_metadata
                            if hasattr(gm, 'web_search_queries') and gm.web_search_queries:
                                for q in gm.web_search_queries:
                                    search_queries.append({"query": q, "tool": "google_search"})
                            elif hasattr(gm, 'search_queries') and gm.search_queries:
                                for q in gm.search_queries:
                                    search_queries.append({"query": q, "tool": "google_search"})
                else:
                    # ë„êµ¬ ë¹„í™œì„±í™”
                    response = self.model.generate_content(full_prompt)
                
                return response.text, search_queries
                
            except Exception as e:
                if attempt < self.max_retries - 1:
                    print(f"âš ï¸ Gemini error, retrying (attempt {attempt + 1}/{self.max_retries})")
                    time.sleep(2 ** attempt)
                else:
                    return f"[Gemini Error: {str(e)}]", []
        
        return "[Gemini Error: All retries failed]", []
    
    def get_model_name(self) -> str:
        return f"Gemini ({self.model_name})"


class GrokClient(BaseAIClient):
    """Grok AI client (xAI) - OpenAI compatible API"""
    
    def __init__(self, api_key: str, model: str = "grok-4"):
        super().__init__()  # Rate limiting ì´ˆê¸°í™”
        if not GROK_AVAILABLE:
            raise ImportError("OpenAI library not available (needed for Grok)")
        self.client = openai.OpenAI(
            api_key=api_key,
            base_url="https://api.x.ai/v1"
        )
        self.model = model
    
    def call(self, system_prompt: str, user_message: str, 
             use_tools: bool = False) -> Tuple[str, List[Dict]]:
        self._rate_limit_check()  # Rate limiting ì ìš©
        
        for attempt in range(self.max_retries):
            try:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ]
            
            search_queries = []
            
            # Grokë„ OpenAI í˜¸í™˜ tool calling ì‚¬ìš©
            tools = []
            if use_tools:
                tools = [{
                    "type": "function",
                    "function": {
                        "name": "web_search",
                        "description": "ìµœì‹  ì˜í•™ ë°ì´í„°ë² ì´ìŠ¤ì™€ ì›¹ ì •ë³´ë¥¼ í†µí•© ê²€ìƒ‰í•˜ì—¬ ì°¨ë“± ì§„ë‹¨ ê·¼ê±°ë¥¼ í™•ë³´í•©ë‹ˆë‹¤. Search latest medical databases and web information to secure differential diagnosis evidence. Includes drug interactions, disease symptoms, treatment guidelines, and recent medical research.",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "query": {
                                    "type": "string",
                                    "description": "ê²€ìƒ‰ ì¿¼ë¦¬ (ì˜í•™ ì •ë³´) / Search query for medical information"
                                }
                            },
                            "required": ["query"]
                        }
                    }
                }]
            
            # ë°˜ë³µ ë£¨í”„: tool_useê°€ ëë‚  ë•Œê¹Œì§€
            # ì˜í•™ ì§„ë‹¨ì—ì„œëŠ” ì•½ë¬¼ê²€ìƒ‰(ë¶€ì‘ìš©/ìƒí˜¸ì‘ìš©) + ì§ˆí™˜ê²€ìƒ‰ ë“± ë³µìˆ˜ ê²€ìƒ‰ì´ í•„ìš”
            max_tool_iterations = 10
            for iteration in range(max_tool_iterations):
                params = {
                    "model": self.model,
                    "messages": messages,
                    "max_tokens": 3000
                }
                if tools:
                    params["tools"] = tools
                    params["tool_choice"] = "auto"
                
                response = self.client.chat.completions.create(**params)
                
                if not response.choices[0].message.tool_calls:
                    return response.choices[0].message.content or "", search_queries
                
                # FIX: message ê°ì²´ë¥¼ dictë¡œ ë³€í™˜
                # FIX #2: tool_calls ê°ì²´ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ dictë¡œ ë³€í™˜
                # FIX V3: tool_call.idë„ ë‚˜ì¤‘ì— ì‚¬ìš©í•˜ë¯€ë¡œ ì €ì¥ í•„ìš”
                tool_calls_dict = []
                tool_call_id_map = {}
                
                if response.choices[0].message.tool_calls:
                    for idx, tc in enumerate(response.choices[0].message.tool_calls):
                        tc_dict = {
                            "id": tc.id,
                            "type": tc.type,
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        }
                        tool_calls_dict.append(tc_dict)
                        tool_call_id_map[idx] = tc.id
                
                assistant_msg = {
                    "role": "assistant",
                    "content": response.choices[0].message.content,
                    "tool_calls": tool_calls_dict
                }
                messages.append(assistant_msg)
                
                for idx, tool_call in enumerate(response.choices[0].message.tool_calls):
                    query = tool_call.function.arguments
                    try:
                        import json as json_module
                        parsed = json_module.loads(query)
                        actual_query = parsed.get("query", query)
                    except Exception:
                        actual_query = query
                    
                    search_queries.append({"query": actual_query, "tool": "web_search"})
                    
                    search_result = self._execute_web_search(actual_query)
                    
                    # FIX V3: tool_call_idëŠ” ë§¤í•‘ì—ì„œ ê°€ì ¸ì˜¤ê¸°
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call_id_map[idx],
                        "content": search_result
                    })
            
            # FIX: ë£¨í”„ ì¢…ë£Œ í›„ ìµœì¢… ì‘ë‹µ - ë¬´í•œ ë£¨í”„ ë°©ì§€
            if messages[-1]["role"] == "tool":
                return "[Max tool iterations reached - pending tool responses]", search_queries
            
            final = self.client.chat.completions.create(
                model=self.model, messages=messages, max_tokens=3000
            )
            return final.choices[0].message.content or "", search_queries
                
            except openai.RateLimitError as e:
                if attempt < self.max_retries - 1:
                    wait_time = 2 ** attempt
                    print(f"âš ï¸ Grok Rate limit, retry in {wait_time}s (attempt {attempt + 1}/{self.max_retries})")
                    time.sleep(wait_time)
                else:
                    return f"[Grok Error: Rate limit exceeded]", []
                    
            except openai.APIError as e:
                if attempt < self.max_retries - 1:
                    print(f"âš ï¸ Grok API error, retrying (attempt {attempt + 1}/{self.max_retries})")
                    time.sleep(1)
                else:
                    return f"[Grok Error: {str(e)}]", []
                    
            except Exception as e:
                return f"[Grok Error: {str(e)}]", []
        
        return "[Grok Error: All retries failed]", []
    
    def _execute_web_search(self, query: str) -> str:
        """
        ìµœì‹  ì˜í•™ ë°ì´í„°ë² ì´ìŠ¤ì™€ ì›¹ ì •ë³´ë¥¼ í†µí•© ê²€ìƒ‰í•˜ì—¬ ì°¨ë“± ì§„ë‹¨ ê·¼ê±°ë¥¼ í™•ë³´í•©ë‹ˆë‹¤.
        Integrate latest medical databases and web information to secure differential diagnosis evidence.
        """
        results = []
        
        try:
            import requests
            from urllib.parse import quote
            
            # ì—¬ëŸ¬ ê²€ìƒ‰ ì—”ì§„ ì‹œë„ (ìˆœì„œëŒ€ë¡œ)
            search_engines = [
                {
                    "name": "Bing",
                    "url": f"https://www.bing.com/search?q={quote(query)}",
                    "snippet_pattern": r'<div class="[^"]*b_caption[^"]*">([^<]+)</div>'
                },
                {
                    "name": "DuckDuckGo Lite", 
                    "url": f"https://lite.duckduckgo.com/lite/?q={quote(query)}",
                    "snippet_pattern": r'<td[^>]*>(.*?)</td>'
                },
                {
                    "name": "Yahoo",
                    "url": f"https://search.yahoo.com/search?p={quote(query)}",
                    "snippet_pattern": r'<p class="[^"]*s-desc[^"]*">([^<]+)</p>'
                }
            ]
            
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            }
            
            for engine in search_engines:
                try:
                    resp = requests.get(engine["url"], headers=headers, timeout=10)
                    
                    if resp.status_code == 200:
                        import re
                        text = resp.text
                        
                        # Scriptì™€ style íƒœê·¸ ì œê±°
                        text = re.sub(r'<script[^>]*>.*?</script>', ' ', text, flags=re.DOTALL | re.IGNORECASE)
                        text = re.sub(r'<style[^>]*>.*?</style>', ' ', text, flags=re.DOTALL | re.IGNORECASE)
                        
                        # ê²€ìƒ‰ ê²°ê³¼ ìŠ¤ë‹ˆí« ì¶”ì¶œ
                        snippets = re.findall(engine["snippet_pattern"], text, re.DOTALL)
                        
                        if snippets:
                            for i, snippet in enumerate(snippets[:5], 1):
                                # HTML íƒœê·¸ ì œê±°
                                clean_snippet = re.sub(r'<[^>]+>', ' ', snippet)
                                clean_snippet = re.sub(r'\s+', ' ', clean_snippet).strip()
                                if clean_snippet and len(clean_snippet) > 20:
                                    results.append(f"Result {i}: {clean_snippet}")
                            
                            if results:
                                return f"[Search via {engine['name']}]\n" + "\n\n".join(results)[:3000]
                
                except Exception as e:
                    # ì´ ì—”ì§„ ì‹¤íŒ¨, ë‹¤ìŒ ì—”ì§„ ì‹œë„
                    continue
            
            # ëª¨ë“  ê²€ìƒ‰ ì—”ì§„ ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ ì •ë³´ ë°˜í™˜
            medical_info = {
                "en": f"Medical query: {query}. Please consult medical databases or professionals for accurate information.",
                "ko": f"ì˜í•™ ê²€ìƒ‰ì–´: {query}. ì •í™•í•œ ì •ë³´ëŠ” ì˜í•™ ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ì „ë¬¸ì˜ì™€ ìƒë‹´í•˜ì„¸ìš”."
            }
            
            return f"[Web search completed]\n{medical_info['ko']}\n{medical_info['en']}"
                
        except ImportError:
            return "[Web search unavailable - requests library not installed]\n[ì›¹ ê²€ìƒ‰ ë¶ˆê°€ - requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜]"
        except Exception as e:
            return f"[Web search error: {str(e)}]\n[ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}]"


class GeminiClient(BaseAIClient):
    """Gemini AI client (Google)"""
    
    def __init__(self, api_key: str, model: str = "gemini-2.0-flash"):
        super().__init__()
        if not GEMINI_AVAILABLE:
            raise ImportError("Google Gemini library not available")
        genai.configure(api_key=api_key)
        self.model_name = model
        
        # FIX: ë„êµ¬ë¥¼ __init__ ì‹œì ì— ë°”ì¸ë”© (ê¶Œì¥ ë°©ì‹)
        # ì´ë ‡ê²Œ í•˜ë©´ ëŸ°íƒ€ì„ ë„êµ¬ ì „ë‹¬ì´ ë¬´ì‹œë˜ëŠ” ë¬¸ì œ ë°©ì§€
        try:
            from google.generativeai import protos
            tools = [protos.Tool(google_search=protos.GoogleSearch())]
            self.model = genai.GenerativeModel(model, tools=tools)
            self.tools_enabled = True
        except ImportError:
            # protos ì‚¬ìš© ë¶ˆê°€ ì‹œ ë„êµ¬ ì—†ì´ ìƒì„±
            self.model = genai.GenerativeModel(model)
            self.tools_enabled = False
    
    def call(self, system_prompt: str, user_message: str, 
             use_tools: bool = False) -> Tuple[str, List[Dict]]:
        self._rate_limit_check()  # Rate limiting ì ìš©
        
        for attempt in range(self.max_retries):
            try:
                full_prompt = f"{system_prompt}\n\n{user_message}"
                
                search_queries = []
                
                # ë„êµ¬ê°€ ì´ë¯¸ __init__ì—ì„œ ë°”ì¸ë”©ë˜ì—ˆìœ¼ë¯€ë¡œ
                # use_tools íŒŒë¼ë¯¸í„°ëŠ” ê²€ìƒ‰ ì¿¼ë¦¬ ì¶”ì¶œ ì—¬ë¶€ë§Œ ì œì–´
                if use_tools and self.tools_enabled:
                    response = self.model.generate_content(full_prompt)
                    
                    # Function call ì²˜ë¦¬ (Gemini 1.5+)
                    if hasattr(response, 'candidates') and response.candidates:
                        candidate = response.candidates[0]
                        
                        # Function call ì²´í¬
                        if hasattr(candidate.content, 'parts'):
                            for part in candidate.content.parts:
                                if hasattr(part, 'function_call') and part.function_call:
                                    # Function call ë°œê²¬
                                    func_call = part.function_call
                                    search_queries.append({
                                        "query": str(func_call.args),
                                        "tool": func_call.name
                                    })
                        
                        # Grounding metadata ì¶”ì¶œ
                        if hasattr(candidate, 'grounding_metadata') and candidate.grounding_metadata:
                            gm = candidate.grounding_metadata
                            if hasattr(gm, 'web_search_queries') and gm.web_search_queries:
                                for q in gm.web_search_queries:
                                    search_queries.append({"query": q, "tool": "google_search"})
                            elif hasattr(gm, 'search_queries') and gm.search_queries:
                                for q in gm.search_queries:
                                    search_queries.append({"query": q, "tool": "google_search"})
                else:
                    # ë„êµ¬ ë¹„í™œì„±í™”
                    response = self.model.generate_content(full_prompt)
                
                return response.text, search_queries
                
            except Exception as e:
                if attempt < self.max_retries - 1:
                    print(f"âš ï¸ Gemini error, retrying (attempt {attempt + 1}/{self.max_retries})")
                    time.sleep(2 ** attempt)
                else:
                    return f"[Gemini Error: {str(e)}]", []
        
        return "[Gemini Error: All retries failed]", []
    
    def get_model_name(self) -> str:
        return f"Grok ({self.model})"


@dataclass
class Doctor:
    """Independent doctor agent with specific AI model"""
    name: str
    specialty: str
    years_experience: int
    personality_traits: List[str]
    ai_provider: AIProvider
    ai_client: BaseAIClient
    language: str = "en"  # Add language parameter
    
    def get_persona_prompt(self) -> str:
        """Generate unique persona for this doctor"""
        traits_str = ", ".join(self.personality_traits)
        
        if self.language == 'ko':
            return f"""ë‹¹ì‹ ì€ {self.name} {self.specialty} ì „ë¬¸ì˜ì…ë‹ˆë‹¤.
ê²½ë ¥: {self.years_experience}ë…„
ì„±ê²©: {traits_str}

ë‹¹ì‹ ì€ ë…ë¦½ì ì¸ ì˜ì‚¬ë¡œì„œ ìì‹ ë§Œì˜ ì˜ê²¬ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
ë‹¤ë¥¸ ì˜ì‚¬ë“¤ê³¼ ì˜ê²¬ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë©°, ê·¸ê²ƒì€ ìì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤.
í•­ìƒ ì˜í•™ì  ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒë‹¨í•˜ë˜, ë‹¹ì‹ ë§Œì˜ ê´€ì ì„ ìœ ì§€í•˜ì„¸ìš”.

ì›¹ ê²€ìƒ‰ì„ ì ê·¹ í™œìš©í•˜ì—¬ ìµœì‹  ì˜í•™ ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
íŠ¹íˆ í¬ê·€ ì§ˆí™˜ì´ë‚˜ ë³µì¡í•œ ì¦ìƒì˜ ê²½ìš° ë°˜ë“œì‹œ ê²€ìƒ‰í•˜ì„¸ìš”.

í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
"""
        else:  # Default English
            return f"""You are Dr. {self.name}, a {self.specialty} specialist.
Experience: {self.years_experience} years
Personality: {traits_str}

You are an independent doctor with your own opinions.
You may disagree with other doctors - this is natural and encouraged.
Always base your judgments on medical evidence, but maintain your unique perspective.

Actively use web search for the latest medical information.
Especially search for rare diseases or complex symptoms.

Respond in English.
"""
    
    def think(self, context: str, question: str, use_web_search: bool = True) -> Tuple[str, List[Dict]]:
        """
        Independent thinking and opinion formation
        """
        system_prompt = self.get_persona_prompt()
        full_message = f"{context}\n\n{question}"
        
        response, searches = self.ai_client.call(
            system_prompt, 
            full_message, 
            use_tools=use_web_search
        )
        
        return response, searches
    
    def __repr__(self):
        return f"Dr. {self.name} ({self.specialty}, {self.ai_client.get_model_name()})"


@dataclass
class Referee:
    """Referee agent with AI model and initialization round"""
    name: str
    ai_provider: AIProvider
    ai_client: BaseAIClient
    initialization_round: int  # Round when this referee is initialized/reset
    language: str = "en"
    memory: List[Dict] = field(default_factory=list)  # FIX: ì‹¬íŒ ê°œì¸ ë©”ëª¨ë¦¬ (ì˜¤ì—¼ ë°©ì§€)
    
    def get_persona_prompt(self) -> str:
        if self.language == 'ko':
            return f"""ë‹¹ì‹ ì€ {self.name}, ê³µì •í•œ ì˜ë£Œ ì§„ë‹¨ ì‹¬íŒì…ë‹ˆë‹¤.
ê²½ë ¥: 30ë…„ ì§„ë‹¨ì˜í•™ ê²½ë ¥

ë‹¹ì‹ ì˜ ì—­í• :
1. ì˜í•™ì  ê·¼ê±°ê°€ ë¶€ì¡±í•œ ì£¼ì¥ ì§€ì 
2. í™˜ê°(hallucination) íƒì§€ (ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì•½ë¬¼, ì¹˜ë£Œë²• ë“±)
3. ì›¹ ê²€ìƒ‰ì„ í†µí•œ ì‚¬ì‹¤ í™•ì¸
4. ë†“ì¹œ ì¤‘ìš”í•œ ê°ë³„ ì§„ë‹¨ ì œì‹œ

âš•ï¸ ì˜ì•½í’ˆ ê²€ì¦ (í•µì‹¬ ì—­í• ):
- í™˜ìê°€ ë³µìš© ì¤‘ì¸ ì•½ë¬¼ì˜ ë¶€ì‘ìš©ì„ ë°˜ë“œì‹œ ê²€ìƒ‰í•˜ì—¬ í™•ì¸
- ì•½ë¬¼ ê°„ ìƒí˜¸ì‘ìš©(drug interaction) ì—¬ë¶€ í™•ì¸
- ì•½ë¬¼ ë¶€ì‘ìš©ì´ í˜„ì¬ ì¦ìƒì„ ìœ ë°œí•  ìˆ˜ ìˆëŠ”ì§€ í‰ê°€
- ì•½ë¬¼ë¡œ ì¸í•œ ì¦ìƒì´ ë‹¤ë¥¸ ì§ˆí™˜ê³¼ í˜¼ë™ë  ìˆ˜ ìˆëŠ”ì§€ íŒë‹¨
- ì˜ˆ: ê³ í˜ˆì••ì•½ â†’ ê¸°ì¹¨, í˜„ê¸°ì¦ / ë‹¹ë‡¨ì•½ â†’ ì €í˜ˆë‹¹ / í•­ê°„ê°„ì§ˆì•½ â†’ ê°„ì†ìƒ ë“±
- ë°˜ë“œì‹œ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ìµœì‹  ì•½ë¬¼ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”

í•­ìƒ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ìµœì‹  ì§„ë‹¨ ê¸°ì¤€ê³¼ ê·¼ê±°ë¥¼ í™•ì¸í•˜ì„¸ìš”.

ë‹¹ì‹ ì€ ì¤‘ë¦½ì ì´ê³  ê°ê´€ì ì…ë‹ˆë‹¤. ëª©í‘œëŠ” ì •í™•í•œ ì§„ë‹¨ì´ì§€ í† ë¡ ì—ì„œ ì´ê¸°ëŠ” ê²ƒì´ ì•„ë‹™ë‹ˆë‹¤.

í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
"""
        else:  # Default English
            return f"""You are {self.name}, an impartial medical diagnosis referee.
Experience: 30 years in diagnostic medicine

Your role:
1. Identify medically unsupported claims
2. Detect hallucinations (non-existent drugs, treatments, etc.)
3. Use web search to fact-check claims
4. Point out missed important differential diagnoses

âš•ï¸ Drug/Medication Verification (CRITICAL responsibility):
- ALWAYS search for side effects of any medication the patient is currently taking
- Check for drug-drug interactions between all medications listed
- Evaluate whether any current symptoms could be CAUSED by medications
- Determine if drug-induced symptoms are being misdiagnosed as other diseases
- Examples: ACE inhibitors â†’ cough, dizziness / Metformin â†’ B12 deficiency / Statins â†’ myopathy
- ALWAYS use web search to verify the latest drug information

Always use web search to verify the latest diagnostic criteria and evidence.

You are neutral and objective. Your goal is accurate diagnosis, not winning debates.

Respond in English.
"""
    
    def evaluate(self, context: str, question: str) -> Tuple[str, List[Dict]]:
        """Evaluate debate and provide feedback"""
        system_prompt = self.get_persona_prompt()
        response, searches = self.ai_client.call(
            system_prompt,
            f"{context}\n\n{question}",
            use_tools=True
        )
        return response, searches
    
    def __repr__(self):
        return f"{self.name} ({self.ai_client.get_model_name()}, init at round {self.initialization_round})"


@dataclass
class Patient:
    """Patient information"""
    age: int
    gender: str
    chief_complaints: List[str]
    history: str
    current_medications: List[str] = field(default_factory=list)  # FIX V3: í˜„ì¬ ë³µìš© ì•½ë¬¼
    allergies: List[str] = field(default_factory=list)  # FIX V3: ì•Œë ˆë¥´ê¸°
    actual_diseases: List[str] = field(default_factory=list)  # For testing


class MultiAIDiagnosisSystem:
    """
    Multi-AI Medical Diagnosis System
    
    Features:
    - Uses multiple AI models (Claude, GPT, Gemini, Grok)
    - Dual referee system with cross-initialization
    - Independent doctors with different AI backends
    - Multi-language support (Korean, English, etc.)
    """
    
    def __init__(self, api_keys: Dict[str, str], language: str = "en"):
        """
        Initialize system with API keys for different providers
        
        Args:
            api_keys: Dictionary with keys 'claude', 'openai', 'gemini', 'grok'
            language: Language code ('en', 'ko', 'es', 'ja', 'zh', etc.)
        """
        self.api_keys = api_keys
        self.doctors: List[Doctor] = []
        self.referees: List[Referee] = []
        self.debate_history: List[Dict] = []
        self.current_round = 0
        self.language = language
        
        # Check available providers
        self.available_providers = []
        if CLAUDE_AVAILABLE and 'claude' in api_keys:
            self.available_providers.append(AIProvider.CLAUDE)
        if OPENAI_AVAILABLE and 'openai' in api_keys:
            self.available_providers.append(AIProvider.GPT)
        if GEMINI_AVAILABLE and 'gemini' in api_keys:
            self.available_providers.append(AIProvider.GEMINI)
        if GROK_AVAILABLE and 'grok' in api_keys:
            self.available_providers.append(AIProvider.GROK)
        
        if not self.available_providers:
            raise ValueError("No AI providers available. Please install libraries and provide API keys.")
        
        print(f"âœ… Available AI providers: {[p.value for p in self.available_providers]}")
        print(f"ğŸŒ Language: {self._get_language_name(language)}")
    
    def _get_language_name(self, code: str) -> str:
        """Get language name from code"""
        languages = {
            'en': 'English',
            'ko': 'í•œêµ­ì–´ (Korean)',
            'es': 'EspaÃ±ol (Spanish)',
            'ja': 'æ—¥æœ¬èª (Japanese)',
            'zh': 'ä¸­æ–‡ (Chinese)',
            'fr': 'FranÃ§ais (French)',
            'de': 'Deutsch (German)'
        }
        return languages.get(code, code)
    
    def _get_language_instruction(self) -> str:
        """Get language instruction for AI prompts"""
        instructions = {
            'en': "Respond in English.",
            'ko': "Respond in Korean (í•œêµ­ì–´).",
            'es': "Responde en espaÃ±ol.",
            'ja': "æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚",
            'zh': "è¯·ç”¨ä¸­æ–‡å›ç­”ã€‚",
            'fr': "RÃ©pondez en franÃ§ais.",
            'de': "Antworten Sie auf Deutsch."
        }
        return instructions.get(self.language, "Respond in English.")
    
    def _translate(self, key: str) -> str:
        """Get translated text for UI elements"""
        translations = {
            'creating_doctors': {
                'en': 'Created {} independent AI doctors:',
                'ko': '{}ëª…ì˜ ë…ë¦½ì ì¸ AI ì˜ì‚¬ ìƒì„± ì™„ë£Œ:'
            },
            'dual_referees': {
                'en': 'Created dual referee system:',
                'ko': 'ì´ì¤‘ ì‹¬íŒ ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ:'
            },
            'referee_reset_schedule': {
                'en': 'â†’ Referee A resets at rounds: 5, 10, 15, 20, ...',
                'ko': 'â†’ ì‹¬íŒ A ì´ˆê¸°í™”: 5, 10, 15, 20, ... ë¼ìš´ë“œ'
            },
            'circular_groups': {
                'en': 'Circular overlap groups:',
                'ko': 'ìˆœí™˜ ì¤‘ì²© ê·¸ë£¹:'
            },
            'active_referee': {
                'en': 'Active referee:',
                'ko': 'í™œì„± ì‹¬íŒ:'
            },
            'resetting_referee': {
                'en': 'Resetting {} (contamination prevention)',
                'ko': '{} ì´ˆê¸°í™” (ì˜¤ì—¼ ì œê±°)'
            },
            'consensus_reached': {
                'en': 'Consensus reached! Diagnosis complete.',
                'ko': 'í•©ì˜ ë„ë‹¬! ì§„ë‹¨ ì™„ë£Œ.'
            },
            'max_rounds': {
                'en': 'Max rounds reached. Outputting current opinions.',
                'ko': 'ìµœëŒ€ ë¼ìš´ë“œ ë„ë‹¬. í˜„ì¬ê¹Œì§€ì˜ ì˜ê²¬ì„ ì¶œë ¥í•©ë‹ˆë‹¤.'
            }
        }
        
        text_dict = translations.get(key, {})
        return text_dict.get(self.language, text_dict.get('en', key))
    
    def _create_ai_client(self, provider: AIProvider) -> BaseAIClient:
        """Create AI client for the specified provider"""
        if provider == AIProvider.CLAUDE:
            return ClaudeClient(self.api_keys['claude'])
        elif provider == AIProvider.GPT:
            return GPTClient(self.api_keys['openai'])
        elif provider == AIProvider.GEMINI:
            return GeminiClient(self.api_keys['gemini'])
        elif provider == AIProvider.GROK:
            return GrokClient(self.api_keys['grok'])
        else:
            raise ValueError(f"Unknown provider: {provider}")
    
    def create_doctor_pool(self, specialties_needed: List[str]) -> None:
        """
        Create pool of doctors using different AI models
        Each specialty gets 2 doctors with different AI backends
        """
        self.doctors = []
        
        personalities = [
            ["ì‹ ì¤‘í•œ", "ë¶„ì„ì ", "ì²´ê³„ì "],
            ["ì ê·¹ì ", "í˜ì‹ ì ", "ë„ì „ì "],
            ["ê³µê°ì ", "ì„¸ì‹¬í•œ", "í™˜ìì¤‘ì‹¬"],
            ["ë…¼ë¦¬ì ", "ê°ê´€ì ", "ê·¼ê±°ì¤‘ì‹¬"],
            ["ê²½í—˜ì ", "ì§ê´€ì ", "í†µì°°ë ¥ìˆëŠ”"],
            ["ë³´ìˆ˜ì ", "ì•ˆì „ì œì¼", "ì›ì¹™ì£¼ì˜"],
            ["í˜‘ì—…ì ", "ì†Œí†µì¤‘ì‹œ", "íŒ€í”Œë ˆì´ì–´"],
            ["ë…ë¦½ì ", "ìê¸°ì£¼ë„ì ", "ê²°ë‹¨ë ¥ìˆëŠ”"]
        ]
        
        surnames = ["ê¹€", "ì´", "ë°•", "ìµœ", "ì •", "ê°•", "ì¡°", "ìœ¤", "ì¥", "ì„"]
        
        provider_index = 0
        used_names = set()  # FIX V3: ì´ë¦„ ì¤‘ë³µ ë°©ì§€
        
        for specialty in specialties_needed:
            for i in range(2):
                # Cycle through available AI providers
                provider = self.available_providers[provider_index % len(self.available_providers)]
                provider_index += 1
                
                # FIX V3: ê³ ìœ í•œ ì´ë¦„ ìƒì„± (ìµœëŒ€ 100ë²ˆ ì‹œë„)
                max_attempts = 100
                for attempt in range(max_attempts):
                    surname = random.choice(surnames)
                    name = f"{surname}{specialty[:2]}{i+1}"
                    if name not in used_names:
                        used_names.add(name)
                        break
                else:
                    # 100ë²ˆ ì‹œë„í•´ë„ ì‹¤íŒ¨í•˜ë©´ ê³ ìœ  ì¸ë±ìŠ¤ ì¶”ê°€
                    name = f"{surname}{specialty[:2]}{i+1}_{len(used_names)}"
                    used_names.add(name)
                
                years = random.randint(7, 25)
                personality = random.choice(personalities)
                
                ai_client = self._create_ai_client(provider)
                
                doctor = Doctor(
                    name=name,
                    specialty=specialty,
                    years_experience=years,
                    personality_traits=personality,
                    ai_provider=provider,
                    ai_client=ai_client,
                    language=self.language  # Pass language to doctor
                )
                self.doctors.append(doctor)
        
        print(f"\nğŸ‘¨â€âš•ï¸ {self._translate('creating_doctors').format(len(self.doctors))}")
        for doc in self.doctors:
            print(f"  - {doc}")
        print()
    
    def create_dual_referees(self) -> None:
        """
        Create dual referee system with cross-initialization
        Referee A: Initialized at rounds 5n (5, 10, 15, ...)
        Referee B: Initialized at rounds 5n-3 (2, 7, 12, ...)
        """
        self.referees = []
        
        # Ensure we have at least 2 different AI providers for referees
        if len(self.available_providers) < 2:
            # Use the same provider but different instances
            provider_a = self.available_providers[0]
            provider_b = self.available_providers[0]
        else:
            provider_a = self.available_providers[0]
            provider_b = self.available_providers[1]
        
        # Referee A: Initialized at 5n (but starts at round 0)
        referee_a = Referee(
            name="Referee A" if self.language == 'en' else "ì‹¬íŒ A",
            ai_provider=provider_a,
            ai_client=self._create_ai_client(provider_a),
            initialization_round=0,  # Will be reset at 5, 10, 15...
            language=self.language
        )
        
        # Referee B: Initialized at 5n-3 (2, 7, 12...)
        referee_b = Referee(
            name="Referee B" if self.language == 'en' else "ì‹¬íŒ B",
            ai_provider=provider_b,
            ai_client=self._create_ai_client(provider_b),
            initialization_round=2,  # Will be reset at 7, 12, 17...
            language=self.language
        )
        
        self.referees = [referee_a, referee_b]
        
        print(f"âš–ï¸ {self._translate('dual_referees')}")
        print(f"  - {referee_a}")
        print(f"  - {referee_b}")
        print(f"  {self._translate('referee_reset_schedule')}")
        if self.language == 'en':
            print(f"  â†’ Referee B resets at rounds: 2, 7, 12, 17, ...")
        else:
            print(f"  â†’ ì‹¬íŒ B ì´ˆê¸°í™”: 2, 7, 12, 17, ... ë¼ìš´ë“œ")
        print()
    
    def should_reset_referee(self, referee: Referee, current_round: int) -> bool:
        """
        Determine if referee should be reset at current round
        FIX V3: initialization_round í•„ë“œë¥¼ ì‹¤ì œë¡œ ì‚¬ìš©í•˜ì—¬ ìœ ì—°ì„± í™•ë³´
        
        Referee A / ì‹¬íŒ A: initialization_round=0 â†’ Reset at 5, 10, 15... (5ì˜ ë°°ìˆ˜)
        Referee B / ì‹¬íŒ B: initialization_round=2 â†’ Reset at 7, 12, 17... (2+5n)
        """
        if current_round == 0:
            return False
        
        # FIX V3: initialization_round ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚° (í•˜ë“œì½”ë”© ì œê±°)
        if referee.initialization_round == 0:
            # 0ì—ì„œ ì‹œì‘ â†’ 5, 10, 15, 20... (5ì˜ ë°°ìˆ˜)
            return current_round % 5 == 0
        else:
            # ë‹¤ë¥¸ ì‹œì‘ì  â†’ (current - init) % 5 == 0
            # ì˜ˆ: init=2 â†’ 2+5=7, 2+10=12, 2+15=17...
            # current=7: (7-2) % 5 = 5 % 5 = 0 âœ“
            return (current_round - referee.initialization_round) % 5 == 0
    
    def reset_referee(self, referee: Referee) -> None:
        """Reset referee by creating new AI client instance"""
        print(f"  ğŸ”„ Resetting {referee.name} (contamination prevention)")
        referee.ai_client = self._create_ai_client(referee.ai_provider)
        # FIX: ì‹¬íŒì˜ ê°œì¸ ë©”ëª¨ë¦¬ë„ ì´ˆê¸°í™” (ì™„ì „í•œ ì˜¤ì—¼ ì œê±°)
        referee.memory = []
    
    def get_active_referee(self, current_round: int) -> Referee:
        """
        Get the active referee for the current round
        Alternates between referees based on round number
        """
        # Use modulo to alternate
        return self.referees[current_round % len(self.referees)]
    
    def create_circular_groups(self) -> List[Tuple[Doctor, Doctor]]:
        """
        Create circular overlap groups with different AI models
        FIX #4: ê°™ì€ ê·¸ë£¹ ë‚´ì—ì„œ ë‹¤ë¥¸ AI ëª¨ë¸ ì‚¬ìš© ë³´ì¥
        FIX V3: ìµœì†Œ ì˜ì‚¬ ìˆ˜ ê²€ì¦ ë° ì¤‘ë³µ ê·¸ë£¹ ë°©ì§€
        """
        n = len(self.doctors)
        
        # FIX V3: ìµœì†Œ 2ëª…ì˜ ì˜ì‚¬ í•„ìš”
        if n < 2:
            raise ValueError(f"At least 2 doctors are required to form groups, but only {n} doctor(s) available")
        
        groups = []
        used_pairs = set()  # ì¤‘ë³µ ê·¸ë£¹ ë°©ì§€
        
        for i in range(n):
            doc1 = self.doctors[i]
            
            # doc1ê³¼ ë‹¤ë¥¸ AIë¥¼ ì‚¬ìš©í•˜ëŠ” ì˜ì‚¬ ì°¾ê¸°
            doc2_candidates = []
            for j in range(1, n):
                candidate_idx = (i + j) % n
                candidate = self.doctors[candidate_idx]
                
                # ìê¸° ìì‹  ì œì™¸ ë° AI ë‹¤ë¥¸ì§€ í™•ì¸
                if candidate_idx != i and candidate.ai_provider != doc1.ai_provider:
                    doc2_candidates.append((candidate_idx, candidate))
            
            # ê°€ì¥ ê°€ê¹Œìš´ ë‹¤ë¥¸ AI ì˜ì‚¬ ì„ íƒ
            if doc2_candidates:
                doc2_idx, doc2 = doc2_candidates[0]
            else:
                # ê°™ì€ AIë§Œ ìˆìœ¼ë©´ ê°€ì¥ ê°€ê¹Œìš´ ë‹¤ë¥¸ ì˜ì‚¬
                doc2_idx = (i + 1) % n
                doc2 = self.doctors[doc2_idx]
            
            # FIX V3: ì¤‘ë³µ ê·¸ë£¹ ë°©ì§€ (ì •ë ¬ëœ íŠœí”Œë¡œ ë¹„êµ)
            pair = tuple(sorted([i, doc2_idx]))
            if pair not in used_pairs:
                groups.append((doc1, doc2))
                used_pairs.add(pair)
        
        print("ğŸ”„ Circular overlap groups (different AI models per group):")
        for idx, (doc1, doc2) in enumerate(groups, 1):
            ai_match = "âš ï¸ SAME AI" if doc1.ai_provider == doc2.ai_provider else "âœ“ Different AI"
            print(f"  Group {idx}: {doc1.name} ({doc1.ai_client.get_model_name()}) + "
                  f"{doc2.name} ({doc2.ai_client.get_model_name()}) [{ai_match}]")
        print()
        
        return groups
    
    def _select_specialties(self, patient: Patient) -> List[str]:
        """Select specialties based on symptoms - supports Korean and English keywords"""
        
        if self.language == 'ko':
            base_specialties = ["ì‹ ê²½ê³¼", "ë‚´ê³¼", "ì •í˜•ì™¸ê³¼", "ë¥˜ë§ˆí‹°ìŠ¤ë‚´ê³¼"]
        else:
            base_specialties = ["Neurology", "Internal Medicine", "Orthopedics", "Rheumatology"]
        
        symptoms_text = " ".join(patient.chief_complaints + [patient.history]).lower()
        
        # Eye-related (Korean + English)
        eye_kr = ["ëˆˆ", "ì‹œë ¥", "ë³µì‹œ", "ì•ˆê²€"]
        eye_en = ["eye", "vision", "double vision", "eyelid", "ptosis", "visual"]
        if any(w in symptoms_text for w in eye_kr + eye_en):
            base_specialties.append("ì•ˆê³¼" if self.language == 'ko' else "Ophthalmology")
        
        # Skin-related
        skin_kr = ["í”¼ë¶€", "ë°œì§„", "ê°€ë ¤ì›€"]
        skin_en = ["skin", "rash", "itch", "dermat"]
        if any(w in symptoms_text for w in skin_kr + skin_en):
            base_specialties.append("í”¼ë¶€ê³¼" if self.language == 'ko' else "Dermatology")
        
        # Cardiac
        cardiac_kr = ["ì‹¬ì¥", "ê°€ìŠ´", "í‰í†µ", "ë‘ê·¼"]
        cardiac_en = ["heart", "chest pain", "palpitation", "cardiac", "chest"]
        if any(w in symptoms_text for w in cardiac_kr + cardiac_en):
            base_specialties.append("ì‹¬ì¥ë‚´ê³¼" if self.language == 'ko' else "Cardiology")
        
        # Respiratory
        resp_kr = ["í˜¸í¡", "ê¸°ì¹¨", "ìˆ¨"]
        resp_en = ["breath", "cough", "respiratory", "lung", "asthma"]
        if any(w in symptoms_text for w in resp_kr + resp_en):
            base_specialties.append("í˜¸í¡ê¸°ë‚´ê³¼" if self.language == 'ko' else "Pulmonology")
        
        # GI
        gi_kr = ["ìœ„", "ê°„", "ë³µí†µ", "ì†Œí™”", "ê°„ì¥"]
        gi_en = ["stomach", "liver", "abdominal", "digestion", "nausea", "bowel"]
        if any(w in symptoms_text for w in gi_kr + gi_en):
            base_specialties.append("ì†Œí™”ë‚´ê³¼" if self.language == 'ko' else "Gastroenterology")
        
        # Headache / Migraine
        head_kr = ["ë‘í†µ", "ë‘ì¥"]
        head_en = ["headache", "migraine", "head pain"]
        if any(w in symptoms_text for w in head_kr + head_en):
            base_specialties.append("ì‹ ê²½ê³¼" if self.language == 'ko' else "Neurology")  # reinforce
        
        # Muscle / fatigue
        muscle_kr = ["ê·¼ìœ¡í†µ", "í”¼ë¡œ", "ê·¼ìœ¡"]
        muscle_en = ["muscle", "fatigue", "weakness", "myalgia"]
        if any(w in symptoms_text for w in muscle_kr + muscle_en):
            base_specialties.append("ë¥˜ë§ˆí‹°ìŠ¤ë‚´ê³¼" if self.language == 'ko' else "Rheumatology")  # reinforce
        
        # Deduplicate while preserving order, then cap at 6
        seen = set()
        unique = []
        for s in base_specialties:
            if s not in seen:
                seen.add(s)
                unique.append(s)
        
        return unique[:6]
    
    def diagnose(self, patient: Patient, max_rounds: int = 5) -> Dict:
        """
        Run diagnosis with multi-AI debate
        """
        print("=" * 80)
        print(f"í™˜ì: {patient.age}ì„¸ {patient.gender}")
        print(f"ì£¼ ì¦ìƒ: {', '.join(patient.chief_complaints)}")
        print(f"ë³‘ë ¥: {patient.history}")
        if patient.actual_diseases:
            print(f"ì‹¤ì œ ì§ˆí™˜ (í…ŒìŠ¤íŠ¸ìš©): {', '.join(patient.actual_diseases)}")
        print("=" * 80)
        print()
        
        # 1. Select specialties
        specialties = self._select_specialties(patient)
        print(f"ğŸ“‹ Selected specialties: {', '.join(specialties)}\n")
        
        # 2. Create doctors
        self.create_doctor_pool(specialties)
        
        # 3. Create dual referees
        self.create_dual_referees()
        
        # 4. Create groups
        groups = self.create_circular_groups()
        
        # 5. Conduct debate
        result = self._conduct_debate(patient, groups, max_rounds)
        
        return result
    
    def _conduct_debate(self, patient: Patient, groups: List[Tuple[Doctor, Doctor]], 
                       max_rounds: int) -> Dict:
        """
        5-stage debate protocol with dual referee system
        """
        if self.language == 'ko':
            context = f"""
í™˜ì ì •ë³´:
- ë‚˜ì´/ì„±ë³„: {patient.age}ì„¸ {patient.gender}
- ì£¼ ì¦ìƒ: {', '.join(patient.chief_complaints)}
- ë³‘ë ¥: {patient.history}
- í˜„ì¬ ë³µìš© ì•½ë¬¼: {', '.join(patient.current_medications) if patient.current_medications else 'ì—†ìŒ'}
- ì•Œë ˆë¥´ê¸°: {', '.join(patient.allergies) if patient.allergies else 'ì—†ìŒ'}
"""
        else:
            context = f"""
Patient Information:
- Age/Gender: {patient.age} years old, {patient.gender}
- Chief Complaints: {', '.join(patient.chief_complaints)}
- Medical History: {patient.history}
- Current Medications: {', '.join(patient.current_medications) if patient.current_medications else 'None'}
- Known Allergies: {', '.join(patient.allergies) if patient.allergies else 'None'}
"""
        
        all_diagnoses = []
        all_searches = []
        previous_rounds = []  # ì´ì „ ë¼ìš´ë“œ í† ë¡  ëˆ„ì  ì €ì¥ì†Œ
        
        for round_num in range(1, max_rounds + 1):
            print(f"\n{'='*80}")
            print(f"Round {round_num}")
            print(f"{'='*80}\n")
            
            self.current_round = round_num
            
            # Check and reset referees if needed
            # ë¦¬ì…‹ ì—¬ë¶€ë¥¼ ë¨¼ì € ê¸°ë¡ (ë¼ìš´ë“œ ê°„ ëˆ„ì  ì œì–´ì— ì‚¬ìš©)
            referee_reset_this_round = {}
            for referee in self.referees:
                if self.should_reset_referee(referee, round_num):
                    self.reset_referee(referee)
                    referee_reset_this_round[referee.name] = True
                else:
                    referee_reset_this_round[referee.name] = False
            
            # Get active referee for this round
            active_referee = self.get_active_referee(round_num)
            print(f"âš–ï¸ Active referee: {active_referee}\n")
            
            # --- ì´ì „ ë¼ìš´ë“œ ì‹¬íŒ í”¼ë“œë°± êµ¬ì„± (ì˜ì‚¬ìš©) ---
            # ì˜ì‚¬ëŠ” í•­ìƒ ì´ì „ ë¼ìš´ë“œì˜ ì‹¬íŒ í”¼ë“œë°±ì„ ë°›ìŒ (í•™ìŠµìš©)
            # FIX V3: ë¦¬ì…‹ëœ ë¼ìš´ë“œëŠ” [RESET_FRESH_VOICE] íƒœê·¸ ì¶”ê°€
            previous_feedback_for_doctors = ""
            if previous_rounds:
                last_round = previous_rounds[-1]
                referee_name = last_round.get('referee_name', 'Unknown')
                was_reset = last_round.get('was_reset', False)
                status = last_round.get('status', 'VALID')
                
                reset_tag = ""
                if was_reset:
                    if self.language == 'ko':
                        reset_tag = "\nâš ï¸ [RESET_FRESH_VOICE] ì´ ì‹¬íŒì€ ë¦¬ì…‹ë˜ì–´ ê³¼ê±° í¸í–¥ì´ ì œê±°ëœ ìƒˆë¡œìš´ ì‹œê°ìœ¼ë¡œ íŒë‹¨í–ˆìŠµë‹ˆë‹¤."
                    else:
                        reset_tag = "\nâš ï¸ [RESET_FRESH_VOICE] This referee was RESET - fresh perspective with no historical bias."
                
                if self.language == 'ko':
                    previous_feedback_for_doctors = f"""
ì´ì „ ë¼ìš´ë“œ ({last_round['round']}) ì‹¬íŒ í”¼ë“œë°± (from {referee_name}):{reset_tag}
{last_round['referee_feedback']}

ìœ„ í”¼ë“œë°±ì„ ì°¸ê³ í•˜ì—¬ ì´ë²ˆ ë¼ìš´ë“œì—ì„œëŠ” ë” ì •í™•í•œ ì§„ë‹¨ì„ ì œì‹œí•˜ì„¸ìš”.
"""
                else:
                    previous_feedback_for_doctors = f"""
Previous round ({last_round['round']}) referee feedback (from {referee_name}):{reset_tag}
{last_round['referee_feedback']}

Please consider the above feedback and provide a more accurate diagnosis this round.
"""
            
            # --- ì‹¬íŒìš© ì´ì „ ë¼ìš´ë“œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ---
            # FIX: ì‹¬íŒë³„ ë…ë¦½ì ì¸ ë©”ëª¨ë¦¬ ì‚¬ìš© (ì˜¤ì—¼ ë°©ì§€)
            # ì‹¬íŒì€ ë¦¬ì…‹ë˜ë©´ ìì‹ ì˜ ë©”ëª¨ë¦¬ê°€ ì´ˆê¸°í™”ë¨
            # ë¦¬ì…‹ë˜ì§€ ì•Šìœ¼ë©´ ìì‹ ì˜ ë©”ëª¨ë¦¬ë§Œ ì°¸ì¡° (ë‹¤ë¥¸ ì‹¬íŒì˜ íŒë‹¨ ì œì™¸)
            previous_context_for_referee = ""
            reset_instruction = ""
            
            if referee_reset_this_round.get(active_referee.name, False):
                # FIX: ë¦¬ì…‹ëœ ì‹¬íŒì—ê²Œ ëª…ì‹œì  ì§€ì¹¨ ì œê³µ
                if self.language == 'ko':
                    reset_instruction = """
âš ï¸ ì¤‘ìš”: ë‹¹ì‹ ì€ í˜„ì¬ ëª¨ë“  í¸í–¥ì´ ì œê±°ëœ ìƒíƒœë¡œ ìƒˆë¡­ê²Œ íˆ¬ì…ë˜ì—ˆìŠµë‹ˆë‹¤.
ì´ì „ ë¼ìš´ë“œì˜ ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” ê²ƒì€ ì˜ë„ëœ ê²ƒì…ë‹ˆë‹¤ (ì˜¤ì—¼ ì œê±°).
ì˜¤ì§ í˜„ì¬ ë¼ìš´ë“œì˜ ë°ì´í„°ë§Œìœ¼ë¡œ ê°ê´€ì ìœ¼ë¡œ íŒë‹¨í•˜ì‹­ì‹œì˜¤.
ê³¼ê±° ë§¥ë½ ë¶€ì¡±ì„ ë¬¸ì œì‚¼ì§€ ë§ê³ , í˜„ì¬ ì˜í•™ì  ì •í™•ì„±ì—ë§Œ ì§‘ì¤‘í•˜ì„¸ìš”.

"""
                else:
                    reset_instruction = """
âš ï¸ IMPORTANT: You have been RESET to eliminate bias contamination.
Previous rounds' context has been intentionally cleared.
You are seeing ONLY the current round's data - this is by design.
Judge ONLY based on current medical accuracy, not historical context.
Do NOT penalize for lack of previous context - focus on current evidence.

"""
            elif active_referee.memory:
                # ë¦¬ì…‹ ì•ˆë¨ â†’ ìì‹ ì˜ ë©”ëª¨ë¦¬ë§Œ ì‚¬ìš© (ë‹¤ë¥¸ ì‹¬íŒ íŒë‹¨ ì œì™¸)
                prev_summaries = []
                for mem in active_referee.memory:
                    prev_summaries.append(
                        f"Round {mem['round']} (your previous judgment):\n"
                        f"  Diagnoses summary: {mem['diagnoses_summary']}\n"
                        f"  Your feedback: {mem['referee_feedback'][:400]}"
                    )
                previous_context_for_referee = "\n\n".join(prev_summaries)
                previous_context_for_referee = f"\n--- Your Previous Judgments (for continuity) ---\n{previous_context_for_referee}\n--- End Previous ---\n"
            
            # STAGE 1: OPINION
            print("ğŸ“ STAGE 1: OPINION\n")
            
            group_opinions = []
            for idx, (doc1, doc2) in enumerate(groups, 1):
                print(f"--- Group {idx}: {doc1.name} ({doc1.ai_client.get_model_name()}) + "
                      f"{doc2.name} ({doc2.ai_client.get_model_name()}) ---")
                
                # Doctor 1 opinion â€” ì´ì „ ì‹¬íŒ í”¼ë“œë°± í¬í•¨
                question1 = f"""
{previous_feedback_for_doctors}
Analyze this patient's symptoms and provide possible diagnoses.
If rare or complex, use web search for latest information.
You will discuss with Dr. {doc2.name}, so provide clear evidence.
"""
                opinion1, searches1 = doc1.think(context, question1, use_web_search=True)
                all_searches.extend(searches1)
                
                print(f"\n[{doc1.name} - {doc1.ai_client.get_model_name()}]")
                if searches1:
                    for s in searches1:
                        print(f"  ğŸ” Search: {s['query']}")
                display1 = opinion1[:500] + ("..." if len(opinion1) > 500 else "")
                print(f"{display1}\n")
                
                time.sleep(1)
                
                # Doctor 2 opinion
                question2 = f"""
{previous_feedback_for_doctors}
Dr. {doc1.name} provided this opinion:

{opinion1}

As an independent doctor, provide your own opinion.
You may agree or disagree with Dr. {doc1.name}.
Use web search for latest information.
"""
                opinion2, searches2 = doc2.think(context, question2, use_web_search=True)
                all_searches.extend(searches2)
                
                print(f"[{doc2.name} - {doc2.ai_client.get_model_name()}]")
                if searches2:
                    for s in searches2:
                        print(f"  ğŸ” Search: {s['query']}")
                display2 = opinion2[:500] + ("..." if len(opinion2) > 500 else "")
                print(f"{display2}\n")
                
                time.sleep(1)
                
                group_opinions.append({
                    "group": idx,
                    "doctors": [doc1.name, doc2.name],
                    "models": [doc1.ai_client.get_model_name(), doc2.ai_client.get_model_name()],
                    "opinion1": opinion1,
                    "opinion2": opinion2
                })
            
            # STAGE 2: REFEREE CHECK
            print(f"\nâš–ï¸ STAGE 2: REFEREE CHECK - {active_referee.name}\n")
            
            all_opinions_text = "\n\n".join([
                f"Group {op['group']} ({', '.join(op['models'])}):\n"
                f"Dr. {op['doctors'][0]}: {op['opinion1'][:800]}"
                + ("..." if len(op['opinion1']) > 800 else "") + "\n"
                f"Dr. {op['doctors'][1]}: {op['opinion2'][:800]}"
                + ("..." if len(op['opinion2']) > 800 else "")
                for op in group_opinions
            ])
            
            referee_question = f"""
{reset_instruction}{previous_context_for_referee}
Review each group's diagnostic opinions:

{all_opinions_text}

Your tasks:
1. Identify medically unsupported claims
2. Detect hallucinations (non-existent drugs, treatments, etc.)
3. Use web search to fact-check each diagnosis
4. Point out missed differential diagnoses

âš•ï¸ MANDATORY drug verification steps - do these FIRST:
- Search: "[each medication the patient takes] side effects"
- Search: "[medication A] [medication B] drug interaction"
- Check: Could any current symptom be caused by a medication?
- Check: Is any diagnosis actually a drug side effect being misidentified?

Patient context for drug checks:
{context}

Use web search to verify latest diagnostic criteria AND drug information.

At the end, output EXACTLY this JSON on a single line (no extra text after it):
{{"consensus_reached": true}}  if consensus IS reached
{{"consensus_reached": false}} if consensus is NOT reached
Do not add any explanation or text after the JSON line.
"""
            
            referee_check, ref_searches = active_referee.evaluate(context, referee_question)
            all_searches.extend(ref_searches)
            
            print(f"[{active_referee.name} - {active_referee.ai_client.get_model_name()}]")
            if ref_searches:
                for s in ref_searches:
                    print(f"  ğŸ” Search: {s['query']}")
            display_ref = referee_check[:500] + ("..." if len(referee_check) > 500 else "")
            print(f"{display_ref}\n")
            
            time.sleep(1)
            
            # --- ì¢…ë£Œ ì¡°ê±´: JSON íŒŒì‹±ìœ¼ë¡œ í•©ì˜ íŒë³„ ---
            consensus_reached = False
            try:
                # FIX: JSON íŒŒì‹± ê°œì„  - ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›
                import re as re_module
                import json as json_module
                
                # FIX #3: ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ë¨¼ì € í™•ì¸
                code_block_match = re_module.search(
                    r'```json\s*\n(.*?)\n```', 
                    referee_check, 
                    re_module.DOTALL | re_module.IGNORECASE
                )
                
                if code_block_match:
                    # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ë‚´ë¶€ì˜ JSON ì‚¬ìš©
                    json_text = code_block_match.group(1).strip()
                else:
                    # ì½”ë“œ ë¸”ë¡ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ê²€ìƒ‰
                    json_text = referee_check
                
                # JSON ë¸”ë¡ ì¶”ì¶œ (ë”°ì˜´í‘œ ì—¬ë¶€ì™€ ë¬´ê´€í•˜ê²Œ)
                json_match = re_module.search(
                    r'\{[^}]*["\']?consensus_reached["\']?\s*:\s*(true|false)[^}]*\}',
                    json_text,
                    re_module.IGNORECASE
                )
                
                if json_match:
                    json_str = json_match.group(0)
                    try:
                        # í‘œì¤€ JSON íŒŒì‹± ì‹œë„
                        data = json_module.loads(json_str)
                        consensus_reached = data.get("consensus_reached", False)
                    except json_module.JSONDecodeError:
                        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì •ê·œì‹ìœ¼ë¡œ true/false ì¶”ì¶œ
                        value_match = re_module.search(r'(true|false)', json_str, re_module.IGNORECASE)
                        if value_match:
                            consensus_reached = value_match.group(1).lower() == "true"
                else:
                    # JSON ì—†ìœ¼ë©´ fallback: ë¶€ì •í˜• ë¨¼ì € ì²´í¬ í›„ ê¸ì •í˜• ì²´í¬
                    lower_check = referee_check.lower()
                    # ë¶€ì •í˜• íŒ¨í„´ ë¨¼ì € í™•ì¸
                    negatives_en = ["not reached", "not yet reached", "not achieved",
                                    "no consensus", "has not been reached", "consensus is not"]
                    negatives_kr = ["ë„ë‹¬í•˜ì§€ ëª»", "í•©ì˜ë˜ì§€ ì•Š", "í•©ì˜ ì•ˆ", "ì•„ì§ í•©ì˜"]
                    
                    is_negative = any(neg in lower_check for neg in negatives_en) or \
                                  any(neg in referee_check for neg in negatives_kr)
                    
                    if not is_negative:
                        # ë¶€ì •í˜• ì—†ëŠ” ê²½ìš°ì—ë§Œ ê¸ì •í˜• í™•ì¸
                        positives_en = ["consensus reached", "consensus achieved",
                                        "consensus has been reached", "reached consensus"]
                        positives_kr = ["í•©ì˜ì— ë„ë‹¬", "í•©ì˜ê°€ ë‹¬ì„±", "í•©ì˜ ë„ë‹¬"]
                        
                        is_positive = any(pos in lower_check for pos in positives_en) or \
                                      any(pos in referee_check for pos in positives_kr)
                        
                        consensus_reached = is_positive
            except Exception:
                consensus_reached = False
            
            # --- í˜„ì¬ ë¼ìš´ë“œ ë°ì´í„°ë¥¼ í™œì„± ì‹¬íŒì˜ ë©”ëª¨ë¦¬ì— ì €ì¥ ---
            # FIX: previous_rounds ì „ì—­ ë¦¬ìŠ¤íŠ¸ ëŒ€ì‹  ì‹¬íŒë³„ ë…ë¦½ ë©”ëª¨ë¦¬ ì‚¬ìš©
            # FIX V3: ë¦¬ì…‹ ì—¬ë¶€ë„ ê¸°ë¡í•˜ì—¬ ë‚˜ì¤‘ì— ì°¸ì¡° ì‹œ ë¬´íš¨í™” ê°€ëŠ¥
            diagnoses_summary = ", ".join([
                f"Group {op['group']}: {op['opinion1'][:150]}"
                for op in group_opinions
            ])
            
            # ë¦¬ì…‹ ì—¬ë¶€ í™•ì¸
            was_reset = referee_reset_this_round.get(active_referee.name, False)
            
            # í™œì„± ì‹¬íŒì˜ ë©”ëª¨ë¦¬ì—ë§Œ ì¶”ê°€ (ë‹¤ë¥¸ ì‹¬íŒì€ ì ‘ê·¼ ë¶ˆê°€)
            active_referee.memory.append({
                "round": round_num,
                "diagnoses_summary": diagnoses_summary,
                "referee_feedback": referee_check,
                "consensus": consensus_reached,
                "was_reset": was_reset  # FIX V3: ë¦¬ì…‹ ì—¬ë¶€ ê¸°ë¡
            })
            
            # previous_roundsëŠ” ë””ë²„ê¹…/ì¶œë ¥ìš©ìœ¼ë¡œë§Œ ìœ ì§€
            # FIX V3: ë¦¬ì…‹ ì •ë³´ í¬í•¨ ë° INVALIDATED ë§ˆí‚¹
            round_record = {
                "round": round_num,
                "referee_name": active_referee.name,
                "diagnoses_summary": diagnoses_summary,
                "referee_feedback": referee_check,
                "consensus": consensus_reached,
                "was_reset": was_reset,
                "status": "INVALIDATED_RESET" if was_reset else "VALID"  # ë¦¬ì…‹ ì‹œ ë¬´íš¨í™” ë§ˆí‚¹
            }
            previous_rounds.append(round_record)
            
            # --- ì¢…ë£Œ íŒì • ---
            if consensus_reached:
                if self.language == 'ko':
                    print("\nâœ… í•©ì˜ ë„ë‹¬! ì§„ë‹¨ ì™„ë£Œ.\n")
                else:
                    print("\nâœ… Consensus reached! Diagnosis complete.\n")
                break
            
            if round_num >= max_rounds:
                if self.language == 'ko':
                    print("\nâš ï¸ ìµœëŒ€ ë¼ìš´ë“œ ë„ë‹¬. í˜„ì¬ê¹Œì§€ì˜ ì˜ê²¬ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n")
                else:
                    print("\nâš ï¸ Max rounds reached. Outputting current opinions.\n")
                break
            
            # Simplified STAGE 3-5 for brevity
            print(f"[Stages 3-5 abbreviated for demo]\n")
        
        result = {
            "patient": patient,
            "diagnoses": group_opinions,
            "total_searches": len(all_searches),
            "rounds": round_num,
            "ai_models_used": list(set([doc.ai_client.get_model_name() for doc in self.doctors])),
            "referee_resets": sum([1 for r in range(1, round_num+1) 
                                  for ref in self.referees 
                                  if self.should_reset_referee(ref, r)])
        }
        
        return result


def example_usage():
    """Example usage of the Multi-AI Diagnosis System"""
    
    # Language selection
    print("\nğŸŒ Select Language / ì–¸ì–´ ì„ íƒ:")
    print("  1. English")
    print("  2. í•œêµ­ì–´ (Korean)")
    print("  3. EspaÃ±ol (Spanish)")
    print("  4. æ—¥æœ¬èª (Japanese)")
    
    lang_choice = input("\nChoice (1-4) [1]: ").strip() or "1"
    
    language_map = {
        '1': 'en',
        '2': 'ko',
        '3': 'es',
        '4': 'ja'
    }
    
    language = language_map.get(lang_choice, 'en')
    
    # Configure API keys
    api_keys = {
        'claude': os.getenv('ANTHROPIC_API_KEY'),
        'openai': os.getenv('OPENAI_API_KEY'),
        'gemini': os.getenv('GEMINI_API_KEY'),
        'grok': os.getenv('GROK_API_KEY')
    }
    
    # Remove None values
    api_keys = {k: v for k, v in api_keys.items() if v is not None}
    
    if not api_keys:
        if language == 'ko':
            print("âŒ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”:")
        else:
            print("âŒ No API keys found. Please set environment variables:")
        print("   export ANTHROPIC_API_KEY='your-key'")
        print("   export OPENAI_API_KEY='your-key'")
        print("   export GEMINI_API_KEY='your-key'")
        print("   export GROK_API_KEY='your-key'")
        return
    
    # Create system with language support
    system = MultiAIDiagnosisSystem(api_keys, language=language)
    
    # Create test patient (with multilingual symptoms)
    if language == 'ko':
        patient = Patient(
            age=42,
            gender="ì—¬ì„±",
            chief_complaints=[
                "ì˜¤í›„ì— ì‹¬í•´ì§€ëŠ” ëˆˆêº¼í’€ ì²˜ì§",
                "ë³µì‹œ",
                "ì €ì‘ ì‹œ í„± í”¼ë¡œ",
                "ì „ì‹  ê·¼ìœ¡í†µ",
                "ë§Œì„± í”¼ë¡œ"
            ],
            history="ìµœê·¼ 6ê°œì›”ê°„ ì¦ìƒì´ ì ì°¨ ì•…í™”ë¨. íŠ¹íˆ ì €ë…ì´ ë˜ë©´ ëˆˆì„ ëœ¨ê¸° í˜ë“¦.",
            current_medications=["ì•„ìŠ¤í”¼ë¦° 100mg", "ë¹„íƒ€ë¯¼ D ë³´ì¶©ì œ"],  # FIX V3: ì•½ë¬¼ ì •ë³´ ì¶”ê°€
            allergies=["í˜ë‹ˆì‹¤ë¦°"],  # FIX V3: ì•Œë ˆë¥´ê¸° ì •ë³´ ì¶”ê°€
            actual_diseases=["ì¤‘ì¦ê·¼ë¬´ë ¥ì¦", "ì„¬ìœ ê·¼ìœ¡í†µ"]
        )
    else:  # English and others
        patient = Patient(
            age=42,
            gender="female",
            chief_complaints=[
                "Worsening eyelid drooping in the afternoon",
                "Double vision",
                "Jaw fatigue while chewing",
                "Generalized muscle pain",
                "Chronic fatigue"
            ],
            history="Symptoms have been gradually worsening over the past 6 months. Especially difficult to open eyes in the evening.",
            current_medications=["Aspirin 100mg", "Vitamin D supplement"],  # FIX V3: Medication info
            allergies=["Penicillin"],  # FIX V3: Allergy info
            actual_diseases=["Myasthenia Gravis", "Fibromyalgia"]
        )
    
    # Run diagnosis
    result = system.diagnose(patient, max_rounds=3)
    
    # Print results
    print("\n" + "="*80)
    if language == 'ko':
        print("ì§„ë‹¨ ê²°ê³¼")
    else:
        print("DIAGNOSIS RESULTS")
    print("="*80)
    
    if language == 'ko':
        print(f"\nì‹¤ì œ ì§ˆí™˜: {', '.join(patient.actual_diseases)}")
        print(f"ë¼ìš´ë“œ: {result['rounds']}")
        print(f"ì´ ê²€ìƒ‰: {result['total_searches']}")
        print(f"ì‚¬ìš©ëœ AI ëª¨ë¸: {', '.join(result['ai_models_used'])}")
        print(f"ì‹¬íŒ ì´ˆê¸°í™”: {result['referee_resets']}íšŒ")
    else:
        print(f"\nActual diseases: {', '.join(patient.actual_diseases)}")
        print(f"Rounds: {result['rounds']}")
        print(f"Total searches: {result['total_searches']}")
        print(f"AI models used: {', '.join(result['ai_models_used'])}")
        print(f"Referee resets: {result['referee_resets']}")


if __name__ == "__main__":
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   Multi-AI Medical Diagnosis System                           â•‘
â•‘   ë‹¤ì¤‘ AI ëª¨ë¸ ê¸°ë°˜ ì˜ë£Œ ì§„ë‹¨ ì‹œìŠ¤í…œ                            â•‘
â•‘                                                                â•‘
â•‘   Features:                                                    â•‘
â•‘   âœ“ Multiple AI models (Claude, GPT, Gemini, Grok)           â•‘
â•‘   âœ“ Each doctor = Different AI backend                       â•‘
â•‘   âœ“ Dual referee with cross-initialization (5n, 5n-3)        â•‘
â•‘   âœ“ Independent API calls                                     â•‘
â•‘   âœ“ Web search integration                                    â•‘
â•‘                                                                â•‘
â•‘   GitHub: https://github.com/[your-repo]                      â•‘
â•‘   License: MIT                                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    example_usage()